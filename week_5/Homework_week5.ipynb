{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa1a0565",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "622560d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/samson/spark/spark-3.0.3-bin-hadoop3.2/jars/spark-unsafe_2.12-3.0.3.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "22/02/28 20:37:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "#start a Spark Session\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0344cb08",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "#### Execute spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01951c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.0.3'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45d275b",
   "metadata": {},
   "source": [
    "### Question 2. HVFHW February 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44fec831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-02-28 20:39:15--  https://nyc-tlc.s3.amazonaws.com/trip+data/fhvhv_tripdata_2021-02.csv\n",
      "Resolving nyc-tlc.s3.amazonaws.com (nyc-tlc.s3.amazonaws.com)... 52.217.235.161\n",
      "Connecting to nyc-tlc.s3.amazonaws.com (nyc-tlc.s3.amazonaws.com)|52.217.235.161|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 733822658 (700M) [text/csv]\n",
      "Saving to: ‘fhvhv_tripdata_2021-02.csv’\n",
      "\n",
      "fhvhv_tripdata_2021 100%[===================>] 699.83M  35.3MB/s    in 21s     \n",
      "\n",
      "2022-02-28 20:39:36 (33.4 MB/s) - ‘fhvhv_tripdata_2021-02.csv’ saved [733822658/733822658]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://nyc-tlc.s3.amazonaws.com/trip+data/fhvhv_tripdata_2021-02.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6449d933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hvfhs_license_num</th>\n",
       "      <th>dispatching_base_num</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>SR_Flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B02764</td>\n",
       "      <td>2021-02-01 00:10:40</td>\n",
       "      <td>2021-02-01 00:21:09</td>\n",
       "      <td>35</td>\n",
       "      <td>39</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B02764</td>\n",
       "      <td>2021-02-01 00:27:23</td>\n",
       "      <td>2021-02-01 00:44:01</td>\n",
       "      <td>39</td>\n",
       "      <td>35</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HV0005</td>\n",
       "      <td>B02510</td>\n",
       "      <td>2021-02-01 00:28:38</td>\n",
       "      <td>2021-02-01 00:38:27</td>\n",
       "      <td>39</td>\n",
       "      <td>91</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HV0005</td>\n",
       "      <td>B02510</td>\n",
       "      <td>2021-02-01 00:43:37</td>\n",
       "      <td>2021-02-01 01:23:20</td>\n",
       "      <td>91</td>\n",
       "      <td>228</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B02872</td>\n",
       "      <td>2021-02-01 00:08:42</td>\n",
       "      <td>2021-02-01 00:17:57</td>\n",
       "      <td>126</td>\n",
       "      <td>250</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  hvfhs_license_num dispatching_base_num      pickup_datetime  \\\n",
       "0            HV0003               B02764  2021-02-01 00:10:40   \n",
       "1            HV0003               B02764  2021-02-01 00:27:23   \n",
       "2            HV0005               B02510  2021-02-01 00:28:38   \n",
       "3            HV0005               B02510  2021-02-01 00:43:37   \n",
       "4            HV0003               B02872  2021-02-01 00:08:42   \n",
       "\n",
       "      dropoff_datetime  PULocationID  DOLocationID  SR_Flag  \n",
       "0  2021-02-01 00:21:09            35            39      NaN  \n",
       "1  2021-02-01 00:44:01            39            35      NaN  \n",
       "2  2021-02-01 00:38:27            39            91      NaN  \n",
       "3  2021-02-01 01:23:20            91           228      NaN  \n",
       "4  2021-02-01 00:17:57           126           250      NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the dataframe schema using pandas \n",
    "\n",
    "pandas_df = pd.read_csv('fhvhv_tripdata_2021-02.csv')\n",
    "\n",
    "pandas_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "376ba41e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hvfhs_license_num        object\n",
       "dispatching_base_num     object\n",
       "pickup_datetime          object\n",
       "dropoff_datetime         object\n",
       "PULocationID              int64\n",
       "DOLocationID              int64\n",
       "SR_Flag                 float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5f603920",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = types.StructType([\n",
    "    types.StructField('hvfhs_license_num', types.StringType(), True),\n",
    "    types.StructField('dispatching_base_num', types.StringType(), True),\n",
    "    types.StructField('pickup_datetime', types.TimestampType(), True),\n",
    "    types.StructField('dropoff_datetime', types.TimestampType(), True),\n",
    "    types.StructField('PULocationID', types.IntegerType(), True),\n",
    "    types.StructField('DOLocationID', types.IntegerType(), True),\n",
    "    types.StructField('SR_Flag', types.StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "29b1e020",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(schema) \\\n",
    "    .csv('fhvhv_tripdata_2021-02.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "90d0c25e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(hvfhs_license_num,StringType,true),StructField(dispatching_base_num,StringType,true),StructField(pickup_datetime,TimestampType,true),StructField(dropoff_datetime,TimestampType,true),StructField(PULocationID,IntegerType,true),StructField(DOLocationID,IntegerType,true),StructField(SR_Flag,StringType,true)))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dcbb5ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.repartition(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa778b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.write.parquet('fhvhv/2021/02/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c033f2aa",
   "metadata": {},
   "source": [
    "### Question 3: Count records\n",
    "\n",
    "#### How many taxi trips were there on February 15?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e66b30c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## register spark df as Temp table\n",
    "df.registerTempTable('fhvhomework_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "57a0117e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:================================================>         (5 + 1) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|  367170|\n",
      "+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select count(*)\n",
    "\n",
    "from fhvhomework_data\n",
    "\n",
    "where DATE(pickup_datetime) = '2021-02-15'\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4b82ea",
   "metadata": {},
   "source": [
    "### Question 4. Longest trip for each day\n",
    "#### Now calculate the duration for each trip. Trip starting on which day was the longest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f18858f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first calculate the trip duration for each trip... pickup_datetime - droppoffdatetime\n",
    "\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8bb68759",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.withColumn(\"trip_duration\", (df.dropoff_datetime - df.pickup_datetime))\n",
    "\n",
    "## register spark df as Temp table\n",
    "df.registerTempTable('fhvhomework_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "08bf09bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 24:================================================>         (5 + 1) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-------------+\n",
      "|    pickup_datetime|   dropoff_datetime|trip_duration|\n",
      "+-------------------+-------------------+-------------+\n",
      "|2021-02-11 13:40:44|2021-02-12 10:39:44|        75540|\n",
      "|2021-02-17 15:54:53|2021-02-18 07:48:34|        57221|\n",
      "|2021-02-20 12:08:15|2021-02-21 00:22:14|        44039|\n",
      "|2021-02-03 20:24:25|2021-02-04 07:41:58|        40653|\n",
      "|2021-02-19 23:17:44|2021-02-20 09:44:01|        37577|\n",
      "|2021-02-25 17:13:35|2021-02-26 02:57:05|        35010|\n",
      "|2021-02-20 01:36:13|2021-02-20 11:16:19|        34806|\n",
      "|2021-02-18 15:24:19|2021-02-19 01:01:11|        34612|\n",
      "|2021-02-18 01:31:20|2021-02-18 11:07:15|        34555|\n",
      "|2021-02-10 20:51:39|2021-02-11 06:21:08|        34169|\n",
      "+-------------------+-------------------+-------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select pickup_datetime,dropoff_datetime,\n",
    "(unix_timestamp(dropoff_datetime) - unix_timestamp(pickup_datetime)) as trip_duration\n",
    "\n",
    "from fhvhomework_data\n",
    "\n",
    "order by trip_duration\n",
    "\n",
    "DESC\n",
    "\n",
    "limit 10\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78569f79",
   "metadata": {},
   "source": [
    "### Question 5. Most frequent dispatching_base_num\n",
    "#### Now find the most frequently occurring dispatching_base_num in this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "54452e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 28:================================================>         (5 + 1) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|dispatching_base_num|count(1)|\n",
      "+--------------------+--------+\n",
      "|              B02510| 3233664|\n",
      "|              B02764|  965568|\n",
      "|              B02872|  882689|\n",
      "|              B02875|  685390|\n",
      "|              B02765|  559768|\n",
      "|              B02869|  429720|\n",
      "|              B02887|  322331|\n",
      "|              B02871|  312364|\n",
      "|              B02864|  311603|\n",
      "|              B02866|  311089|\n",
      "|              B02878|  305185|\n",
      "|              B02682|  303255|\n",
      "|              B02617|  274510|\n",
      "|              B02883|  251617|\n",
      "|              B02884|  244963|\n",
      "|              B02882|  232173|\n",
      "|              B02876|  215693|\n",
      "|              B02879|  210137|\n",
      "|              B02867|  200530|\n",
      "|              B02877|  198938|\n",
      "+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select dispatching_base_num,\n",
    "count(1)\n",
    "\n",
    "from fhvhomework_data\n",
    "\n",
    "group by 1\n",
    "order by 2\n",
    "DESC\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a5f72d",
   "metadata": {},
   "source": [
    "### Question 6. Most common locations pair\n",
    "#### Find the most common pickup-dropoff pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9d4892a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-02-28 22:31:09--  https://s3.amazonaws.com/nyc-tlc/misc/taxi+_zone_lookup.csv\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.67.134\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.67.134|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12322 (12K) [application/octet-stream]\n",
      "Saving to: ‘taxi+_zone_lookup.csv’\n",
      "\n",
      "taxi+_zone_lookup.c 100%[===================>]  12.03K  --.-KB/s    in 0s      \n",
      "\n",
      "2022-02-28 22:31:09 (142 MB/s) - ‘taxi+_zone_lookup.csv’ saved [12322/12322]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#We need to join on the zones table\n",
    "\n",
    "!wget https://s3.amazonaws.com/nyc-tlc/misc/taxi+_zone_lookup.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bd8d73e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LocationID</th>\n",
       "      <th>Borough</th>\n",
       "      <th>Zone</th>\n",
       "      <th>service_zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>EWR</td>\n",
       "      <td>Newark Airport</td>\n",
       "      <td>EWR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Queens</td>\n",
       "      <td>Jamaica Bay</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>Allerton/Pelham Gardens</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Alphabet City</td>\n",
       "      <td>Yellow Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>Arden Heights</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LocationID        Borough                     Zone service_zone\n",
       "0           1            EWR           Newark Airport          EWR\n",
       "1           2         Queens              Jamaica Bay    Boro Zone\n",
       "2           3          Bronx  Allerton/Pelham Gardens    Boro Zone\n",
       "3           4      Manhattan            Alphabet City  Yellow Zone\n",
       "4           5  Staten Island            Arden Heights    Boro Zone"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zones_pd = pd.read_csv('taxi+_zone_lookup.csv')\n",
    "\n",
    "zones_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9c4be0d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LocationID</th>\n",
       "      <th>Borough</th>\n",
       "      <th>Zone</th>\n",
       "      <th>service_zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>261</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>World Trade Center</td>\n",
       "      <td>Yellow Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>262</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Yorkville East</td>\n",
       "      <td>Yellow Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>263</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Yorkville West</td>\n",
       "      <td>Yellow Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>264</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NV</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>265</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     LocationID    Borough                Zone service_zone\n",
       "260         261  Manhattan  World Trade Center  Yellow Zone\n",
       "261         262  Manhattan      Yorkville East  Yellow Zone\n",
       "262         263  Manhattan      Yorkville West  Yellow Zone\n",
       "263         264    Unknown                  NV          NaN\n",
       "264         265    Unknown                 NaN          NaN"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zones_pd.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8c17038c",
   "metadata": {},
   "outputs": [],
   "source": [
    "zones = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv('taxi+_zone_lookup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d0718a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "## register spark df as Temp table\n",
    "zones.registerTempTable('zones')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6ed8704c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 50:================================================>         (5 + 1) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+--------+\n",
      "|PULocationID|DOLocationID|count(1)|\n",
      "+------------+------------+--------+\n",
      "|          76|          76|   45041|\n",
      "|          26|          26|   37329|\n",
      "|          39|          39|   28026|\n",
      "|          61|          61|   25976|\n",
      "|          14|          14|   17934|\n",
      "|           7|           7|   14688|\n",
      "|         129|         129|   14688|\n",
      "|          42|          42|   14481|\n",
      "|          37|          37|   14424|\n",
      "|          89|          89|   13976|\n",
      "|         216|         216|   13716|\n",
      "|          35|          35|   12829|\n",
      "|         132|         265|   12542|\n",
      "|         188|          61|   11814|\n",
      "|          95|          95|   11548|\n",
      "|          36|          37|   11491|\n",
      "|          37|          36|   11487|\n",
      "|          61|         188|   11462|\n",
      "|          61|         225|   11342|\n",
      "|         188|         188|   11308|\n",
      "+------------+------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select PULocationID,DOLocationID,\n",
    "count(*)\n",
    "\n",
    "from fhvhomework_data\n",
    "left join zones on fhvhomework_data.PULocationID == zones.LocationID\n",
    "\n",
    "group by DOLocationID,PULocationID\n",
    "order by 3\n",
    "DESC\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ac86a655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|         Zone|\n",
      "+-------------+\n",
      "|East New York|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "zones.select('Zone').filter(zones.LocationID == '76').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4205695",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
